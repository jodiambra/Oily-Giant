{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OilyGiant Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this project is to find the best location for a our customer, OilyGiant, to place a new well for mining oil. We are given oil well parameters in three distinct regions, upon which we will use to create our linear regression model. The model will predict the volume of reserves in the new wells, and the region with the highest total profit will be chosen for the new well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error as mse, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from scipy import stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read datasets \n",
    "df0 = pd.read_csv('datasets/geo_data_0.csv')\n",
    "df1 = pd.read_csv('datasets/geo_data_1.csv')\n",
    "df2 = pd.read_csv('datasets/geo_data_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 5)\n",
      "(100000, 5)\n",
      "(100000, 5)\n"
     ]
    }
   ],
   "source": [
    "# Shape of datasets \n",
    "print(df0.shape)\n",
    "print(df1.shape)\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id         0\n",
      "f0         0\n",
      "f1         0\n",
      "f2         0\n",
      "product    0\n",
      "dtype: int64\n",
      "\n",
      "id         0\n",
      "f0         0\n",
      "f1         0\n",
      "f2         0\n",
      "product    0\n",
      "dtype: int64\n",
      "\n",
      "id         0\n",
      "f0         0\n",
      "f1         0\n",
      "f2         0\n",
      "product    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(df0.isnull().sum())\n",
    "print()\n",
    "print(df1.isnull().sum())\n",
    "print()\n",
    "print(df2.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "\n",
      "0\n",
      "\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "print(df0.duplicated().sum())\n",
    "print()\n",
    "print(df1.duplicated().sum())\n",
    "print()\n",
    "print(df2.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First dataset:\n",
      "f0         0.143536\n",
      "f1        -0.192356\n",
      "f2         0.483663\n",
      "product    1.000000\n",
      "Name: product, dtype: float64\n",
      "\n",
      "Second dataset:\n",
      "f0        -0.030491\n",
      "f1        -0.010155\n",
      "f2         0.999397\n",
      "product    1.000000\n",
      "Name: product, dtype: float64\n",
      "\n",
      "Third dataset:\n",
      "f0        -0.001987\n",
      "f1        -0.001012\n",
      "f2         0.445871\n",
      "product    1.000000\n",
      "Name: product, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# correlation between features and target\n",
    "print('First dataset:')\n",
    "print(df0.corr()['product'])\n",
    "print()\n",
    "\n",
    "# correlation between features and target\n",
    "print('Second dataset:')\n",
    "print( df1.corr()['product'])\n",
    "print()\n",
    "\n",
    "# correlation between features and target\n",
    "print('Third dataset:')\n",
    "print(df2.corr()['product'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data did not need to be cleaned, as there were neither missing values nor duplicates found. This is crucial, as our models cannot run with missing or duplicates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99990\n",
      "99996\n",
      "99996\n"
     ]
    }
   ],
   "source": [
    "print(df0.id.nunique())\n",
    "print(df1.id.nunique())\n",
    "print(df2.id.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most ID's are unique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First dataset\n",
    "target_0 = df0['product']\n",
    "features_0 = df0.drop(['product', 'id'], axis=1)\n",
    "\n",
    "# Second dataset\n",
    "target_1 = df1['product']\n",
    "features_1 = df1.drop(['product', 'id'], axis=1)\n",
    "\n",
    "# Third dataset\n",
    "target_2 = df2['product']\n",
    "features_2 = df2.drop(['product', 'id'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropped the categorical id column in order to run the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random state variable\n",
    "random_state = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into train and valid sets, 75/25 \n",
    "\n",
    "# First dataset\n",
    "features_train_0, features_valid_0, target_train_0, target_valid_0 = train_test_split(features_0, target_0, test_size=0.25, random_state=random_state)\n",
    "\n",
    "# Second dataset\n",
    "features_train_1, features_valid_1, target_train_1, target_valid_1 = train_test_split(features_1, target_1, test_size=0.25, random_state=random_state)\n",
    "\n",
    "# Third dataset\n",
    "features_train_2, features_valid_2, target_train_2, target_valid_2 = train_test_split(features_2, target_2, test_size=0.25, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75000, 3)\n",
      "(75000,)\n",
      "(25000, 3)\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "# Shape of results\n",
    "print(features_train_0.shape)\n",
    "print(target_train_0.shape)\n",
    "print(features_valid_0.shape)\n",
    "print(target_valid_0.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Function\n",
    "def linear_model(ft, tt, fv, tv, n): # features_train, target_train, features_valid, target_valid, dataset number\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(ft, tt) # train model on training set\n",
    "    predictions_valid = model.predict(fv) # get model predictions on validation set\n",
    "    result = mse(tv, predictions_valid) ** 0.5 # calculate RMSE on validation set\n",
    "           \n",
    "    print('RMSE of the linear regression model on the validation set:', result)\n",
    "    print('Dataset number :', (n))\n",
    "    print('R2 score: ', r2_score(tv, predictions_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of the linear regression model on the validation set: 37.489176404931385\n",
      "Dataset number : 0\n",
      "R2 score:  0.2800427586322962\n"
     ]
    }
   ],
   "source": [
    "# Dataset 0\n",
    "linear_model(features_train_0, target_train_0, features_valid_0, target_valid_0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of the linear regression model on the validation set: 0.8949747975866225\n",
      "Dataset number : 1\n",
      "R2 score:  0.9996221715647515\n"
     ]
    }
   ],
   "source": [
    "# Dataset 1\n",
    "linear_model(features_train_1, target_train_1, features_valid_1, target_valid_1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of the linear regression model on the validation set: 40.03911711877307\n",
      "Dataset number : 2\n",
      "R2 score:  0.19763128804301888\n"
     ]
    }
   ],
   "source": [
    "# Dataset 2\n",
    "linear_model(features_train_2, target_train_2, features_valid_2, target_valid_2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear model with the highest quality was with dataset 1. That model had a coefficient of determination, R^2, of .0999. This means the model almost perfectly predicts all the targets. This model also had the lowest RMSE. The models did not perform as well with datasets 0 and 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 0\n",
    "model_0 = LinearRegression()\n",
    "model_0.fit(features_train_0, target_train_0) # train model on training set\n",
    "\n",
    "# Predictions for model 0\n",
    "predictions_0 = model_0.predict(features_valid_0)\n",
    "predictions_0 = pd.Series(predictions_0)\n",
    "\n",
    "# Merged dataframe of target and predictions \n",
    "merged_0 = pd.concat([target_valid_0.reset_index(drop=True), predictions_0], axis=1)\n",
    "merged_0.columns = ['target', 'predictions']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1\n",
    "model_1 = LinearRegression()\n",
    "model_1.fit(features_train_1, target_train_1) # train model on training set\n",
    "\n",
    "# Predictions for model 1\n",
    "predictions_1 = model_1.predict(features_valid_1)\n",
    "predictions_1 = pd.Series(predictions_1)\n",
    "\n",
    "# Merged dataframe of target and predictions \n",
    "merged_1 = pd.concat([target_valid_1.reset_index(drop=True), predictions_1], axis=1)\n",
    "merged_1.columns = ['target', 'predictions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2\n",
    "model_2 = LinearRegression()\n",
    "model_2.fit(features_train_2, target_train_2) # train model on training set\n",
    "\n",
    "predictions_2 = model_2.predict(features_valid_2)\n",
    "predictions_2 = pd.Series(predictions_2)\n",
    "\n",
    "merged_2 = pd.concat([target_valid_2.reset_index(drop=True), predictions_2], axis=1)\n",
    "merged_2.columns = ['target', 'predictions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we trained our models with the various datasets to create the predictions on well volume. We then merged these predictions to their corresponding targets to create one dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Predictions 0: 92.42951694121892          Stdev Predictions 0: 23.25461037847274\n",
      "Mean Predictions 1: 68.68102185200009          Stdev Predictions 1: 46.0429779067258\n",
      "Mean Predictions 2: 94.91135196705469          Stdev Predictions 2: 19.79760332480081\n"
     ]
    }
   ],
   "source": [
    "print('Mean Predictions 0:', predictions_0.mean(), '        ', 'Stdev Predictions 0:', predictions_0.std())\n",
    "print('Mean Predictions 1:', predictions_1.mean(),'        ', 'Stdev Predictions 1:', predictions_1.std())\n",
    "print('Mean Predictions 2:', predictions_2.mean(), '        ', 'Stdev Predictions 2:', predictions_2.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The budget for development of 200 oil wells is 100 USD million.\n",
    "One barrel of raw materials brings 4.5 USD of revenue The revenue from one unit of product is 4,500 dollars (volume of reserves is in thousand barrels). It appears that Region 2 has the highest average predicted well volume reserve. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Region 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target         2.311242e+06\n",
       "predictions    2.310738e+06\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing target and predictions of dataset 0 \n",
    "merged_0.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>25000.0</td>\n",
       "      <td>92.449669</td>\n",
       "      <td>44.183614</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56.610227</td>\n",
       "      <td>91.61242</td>\n",
       "      <td>128.522832</td>\n",
       "      <td>185.355615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictions</th>\n",
       "      <td>25000.0</td>\n",
       "      <td>92.429517</td>\n",
       "      <td>23.254610</td>\n",
       "      <td>-9.764724</td>\n",
       "      <td>76.659319</td>\n",
       "      <td>92.45290</td>\n",
       "      <td>108.449070</td>\n",
       "      <td>180.227277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count       mean        std       min        25%       50%  \\\n",
       "target       25000.0  92.449669  44.183614  0.000000  56.610227  91.61242   \n",
       "predictions  25000.0  92.429517  23.254610 -9.764724  76.659319  92.45290   \n",
       "\n",
       "                    75%         max  \n",
       "target       128.522832  185.355615  \n",
       "predictions  108.449070  180.227277  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing target and predictions of dataset 0 \n",
    "merged_0.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Region 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target         1.716792e+06\n",
       "predictions    1.717026e+06\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing target and predictions of dataset 1\n",
    "merged_1.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>25000.0</td>\n",
       "      <td>68.671662</td>\n",
       "      <td>46.043907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.953261</td>\n",
       "      <td>57.085625</td>\n",
       "      <td>107.813044</td>\n",
       "      <td>137.945408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictions</th>\n",
       "      <td>25000.0</td>\n",
       "      <td>68.681022</td>\n",
       "      <td>46.042978</td>\n",
       "      <td>-2.061922</td>\n",
       "      <td>28.391403</td>\n",
       "      <td>58.319042</td>\n",
       "      <td>109.280975</td>\n",
       "      <td>139.984148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count       mean        std       min        25%        50%  \\\n",
       "target       25000.0  68.671662  46.043907  0.000000  26.953261  57.085625   \n",
       "predictions  25000.0  68.681022  46.042978 -2.061922  28.391403  58.319042   \n",
       "\n",
       "                    75%         max  \n",
       "target       107.813044  137.945408  \n",
       "predictions  109.280975  139.984148  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing target and predictions of dataset 1\n",
    "merged_1.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Region 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target         2.376934e+06\n",
       "predictions    2.372784e+06\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing target and predictions of dataset 2\n",
    "merged_2.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>25000.0</td>\n",
       "      <td>95.077342</td>\n",
       "      <td>44.699862</td>\n",
       "      <td>0.009204</td>\n",
       "      <td>59.634772</td>\n",
       "      <td>94.882039</td>\n",
       "      <td>130.685889</td>\n",
       "      <td>190.029838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictions</th>\n",
       "      <td>25000.0</td>\n",
       "      <td>94.911352</td>\n",
       "      <td>19.797603</td>\n",
       "      <td>16.341091</td>\n",
       "      <td>81.549013</td>\n",
       "      <td>94.925208</td>\n",
       "      <td>108.410820</td>\n",
       "      <td>173.959528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count       mean        std        min        25%        50%  \\\n",
       "target       25000.0  95.077342  44.699862   0.009204  59.634772  94.882039   \n",
       "predictions  25000.0  94.911352  19.797603  16.341091  81.549013  94.925208   \n",
       "\n",
       "                    75%         max  \n",
       "target       130.685889  190.029838  \n",
       "predictions  108.410820  173.959528  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing target and predictions of dataset 2\n",
    "merged_2.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing targets and predictions across all datasets, we can see that our models were excellent. The mean an sum of our target and predictions columns are identical across all three datasets. The metrics that are different are the standard deviation, min, and max values. Again, Region 2 has the highest mean and total barrel reserve volume. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Break Even Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost per barrel\n",
    "cpb = 4.5 \n",
    "\n",
    "# budget\n",
    "budget = 100000000\n",
    "\n",
    "# Number of wells\n",
    "wells = 200\n",
    "\n",
    "# Factor for unit of barrels\n",
    "factor = 1000\n",
    "\n",
    "unit_cost = 4500\n",
    "\n",
    "# Budget per well\n",
    "bpw = budget / wells\n",
    "\n",
    "# Budget per barrel\n",
    "bpb = bpw / unit_cost\n",
    "\n",
    "# Break even reserve volume\n",
    "break_even = budget / (cpb * factor)\n",
    "\n",
    "# Minimum volume to break even\n",
    "min_product = break_even / wells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume in region 0 after break even:  -18.66144208004802 barrels\n",
      "Volume in region 1 after break even:  -42.43944890421423 barrels\n",
      "Volume in region 2 after break even:  -16.033768694089275 barrels\n"
     ]
    }
   ],
   "source": [
    "# Comparing mean volume with break even point\n",
    "print('Volume in region 0 after break even: ', f'{merged_0.target.mean() - (min_product):,}', 'barrels')\n",
    "print('Volume in region 1 after break even: ', f'{merged_1.target.mean() - (min_product):,}', 'barrels')\n",
    "print('Volume in region 2 after break even: ', f'{merged_2.target.mean() - (min_product):,}', 'barrels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Break even metric is compared with the mean of the complete regional datasets, comparing the target values. Here, we see that the mean targets are all lower than the minimum volume of oil needed to break even. This evaluation is misleading, as some wells will be far more profitable than other wells. Furthermore, it is in the interest of the company to exclusively pick wells with the highest profit, and avoid wells that do not break even. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profit of Selected Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to determine profit predictions to target\n",
    "def profit(target, predictions, count):\n",
    "    predictions_sorted = predictions.sort_values(ascending=False)\n",
    "    selected = target[predictions_sorted.index][:count]\n",
    "    return (unit_cost * selected.sum()) - budget\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Profit takes into consideration the budget of 200 wells at $100 million. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profit per Top 200 Wells per Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total profit from Region 0 : $ -16,617,291.92250064\n",
      "Total profit from Region 1 : $ -37,881,648.63171914\n",
      "Total profit from Region 2 : $ -16,543,855.132537901\n"
     ]
    }
   ],
   "source": [
    "print('Total profit from Region 0 :', '$', f'{profit(target_0, predictions_0, 200 ):,}')\n",
    "print('Total profit from Region 1 :', '$', f'{profit(target_1, predictions_1, 200 ):,}')\n",
    "print('Total profit from Region 2 :', '$', f'{profit(target_2, predictions_2, 200 ):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the the data of the top 200 wells of each region, Region 2 will bring the most profit. This data is based on target values of the largest 200 model predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk and Profit for each Region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for confidence interval\n",
    "def confidence(sample): \n",
    "    print('Mean:', sample.mean())\n",
    "    confidence_interval = st.t.interval(0.95, len(sample)-1, sample.mean(), sample.sem())\n",
    "    print('95% confidence interval:', confidence_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 92.42951694121892\n",
      "95% confidence interval: (92.141241144103, 92.71779273833484)\n"
     ]
    }
   ],
   "source": [
    "confidence(predictions_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 68.68102185200009\n",
      "95% confidence interval: (68.11025003765316, 69.25179366634701)\n"
     ]
    }
   ],
   "source": [
    "confidence(predictions_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 94.91135196705469\n",
      "95% confidence interval: (94.66593096078726, 95.1567729733221)\n"
     ]
    }
   ],
   "source": [
    "confidence(predictions_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This confirms the earlier theory in the distribution of the well values among the regions. Region 2 values are slightly higher than Region 1. Region 0 is mostly distributed around smaller values of barrel reserve volume. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profit Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for determining profit, risk, and losses \n",
    "def profit_risk(target, predictions):\n",
    "    state = np.random.RandomState(19)\n",
    "    values = []\n",
    "    for i in range(1000):\n",
    "        target_subsample = target.sample(n=500, replace=True, random_state=state)\n",
    "        pred_subsample = predictions[target_subsample.index]\n",
    "        values.append(profit(target_subsample, pred_subsample, 200))\n",
    "\n",
    "    values = pd.Series(values)\n",
    "    losses = (values < 0 ).mean() * 100\n",
    "   \n",
    "\n",
    "    print((f'{values.quantile(0.025):,}', f'{values.quantile(0.975):,}'))\n",
    "    print('Mean Profit: ', f'{values.mean():,}')\n",
    "    print('Losses : ', losses)   \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Region 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('-682,314.259189359', '9,774,510.185401097')\n",
      "Mean Profit:  4,533,870.619212874\n",
      "Losses :  4.8\n"
     ]
    }
   ],
   "source": [
    "# Region 0\n",
    "profit_risk(merged_0.target, merged_0.predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Region 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('681,283.8236853313', '8,630,951.198799688')\n",
      "Mean Profit:  4,945,452.4751050165\n",
      "Losses :  1.0999999999999999\n"
     ]
    }
   ],
   "source": [
    "# Region 1\n",
    "profit_risk(merged_1.target, merged_1.predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Region 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('-1,538,054.1441032141', '9,219,736.453033209')\n",
      "Mean Profit:  3,756,892.0224074163\n",
      "Losses :  8.3\n"
     ]
    }
   ],
   "source": [
    "# Region 2\n",
    "profit_risk(merged_2.target, merged_2.predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the mean profit, Region 1 has the highest profit potential. Furthermore, Region 1 has the lowest chance of losses, at just over 1%. The 95% confidence zone of Region 1, has the highest range for profit. Regions 0 and  2 have 4.8 and 8.3 % chances of losses, respectively. This is supported by negative profit values seen in the 95% confidence interval. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the three datasets, we will suggest OilGiant to start a new site in Region 1. Region 1 has the greatest profit margin, as the range of well reserve volume is better than those of the other regions, due to the higher lower bound. In addition, the chance of losses in Region 1 is around 1%, which is extremely low. Therefore, the chances of randomly picking 200 sites that are extremely profitable will be more likely in Region 1. As we are focusing on as subsample of the 200 most profitable wells out of a 500 well sample, we limit our chance of loss, rather than just randomly picking wells. Overall, our model will perform well when predicting new sites to implement, and predicting the most profitable wells, given the same features we have in our model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "4f2b0cfe12c109b58467a02dc33230d9e6228c23b43020d2941c37e2a7dfdd3f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
